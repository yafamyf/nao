{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baf0bd5d",
   "metadata": {},
   "source": [
    "# Acquisition de donn√©es de poses pour entra√Ænement de mod√®les\n",
    "\n",
    "Ce notebook a pour objectif de :\n",
    "- Initialiser la capture vid√©o √† partir de la cam√©ra de l‚Äôordinateur.\n",
    "- Utiliser MediaPipe pour d√©tecter les landmarks (points cl√©s) de la pose humaine.\n",
    "- Afficher en temps r√©el le squelette d√©tect√© sur l‚Äôimage.\n",
    "- Permettre la capture d‚Äôune pose particuli√®re (au clavier) pour la stocker.\n",
    "- Sauvegarder l‚Äôensemble des poses captur√©es dans un fichier CSV (`poses_capturees.csv`), o√π chaque ligne contient les coordonn√©es X et Y des 33 landmarks (66 colonnes).\n",
    "- Documenter chaque √©tape en fran√ßais pour faciliter la compr√©hension et la r√©utilisation.\n",
    "\n",
    "**Instructions d‚Äôutilisation :**\n",
    "1. Cliquez dans la cellule d‚Äôacquisition (#5) et ex√©cutez-la.\n",
    "2. Une fen√™tre s‚Äôouvre avec le flux vid√©o et le squelette d√©tect√©.\n",
    "3. Appuyez sur la touche **`a`** pour capturer la pose courante (elle sera ajout√©e √† la liste interne).\n",
    "4. Appuyez sur **`q`** ou **`Esc`** pour quitter et sauvegarder toutes les poses dans `poses_capturees.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa6ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Imports n√©cessaires pour la capture vid√©o, le traitement MediaPipe,\n",
    "# l‚Äôaffichage et la sauvegarde CSV\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import cv2                              # OpenCV pour la capture webcam et l‚Äôaffichage\n",
    "import mediapipe as mp                  # MediaPipe pour la d√©tection de la pose\n",
    "import csv                              # Pour √©crire les coordonn√©es dans un fichier CSV\n",
    "import os                               # Pour v√©rifier ou cr√©er le dossier de sortie\n",
    "\n",
    "from pose import Pose # Importation de la classe Pose d√©finie dans le fichier pose.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271c62cf",
   "metadata": {},
   "source": [
    "## Explications et conseils d‚Äôutilisation\n",
    "\n",
    "1. **Initialisation**  \n",
    "   - Nous avons configur√© les param√®tres MediaPipe (`MIN_DETECTION_CONFIDENCE`, `MIN_TRACKING_CONFIDENCE`, `MODEL_COMPLEXITY`) pour un compromis entre rapidit√© et pr√©cision.  \n",
    "   - `VIDEO_SOURCE = 0` correspond √† la premi√®re cam√©ra disponible. Si vous avez plusieurs cam√©ras, vous pouvez essayer `1`, `2`, etc.\n",
    "\n",
    "2. **D√©tection en temps r√©el**  \n",
    "   - √Ä chaque it√©ration de la boucle, on lit une image depuis la cam√©ra, on la convertit en RGB puis on fait `pose.process(image_rgb)`.  \n",
    "   - Si des landmarks sont d√©tect√©s (`results.pose_landmarks`), on les dessine sur l‚Äôimage avec `draw_landmarks`.\n",
    "\n",
    "3. **Capture d‚Äôune pose**  \n",
    "   - Lorsque vous appuyez sur la touche **`a`**, on appelle `pose_tracker._toVector(results.pose_landmarks)` qui renvoie une liste de 66 coordonn√©es (33 points √ó (x,y)).  \n",
    "   - Si aucun landmark n‚Äôest d√©tect√©, la liste est vide et on ignore cette capture. Sinon, on ajoute la liste √† `pose_data`.\n",
    "\n",
    "4. **Arr√™t et sauvegarde**  \n",
    "   - Lorsque vous appuyez sur **`q`** ou **`Esc`**, on sort de la boucle, on ouvre (ou cr√©e) `poses_capturees.csv` dans le dossier `data_poses/` puis on √©crit toutes les lignes de `pose_data`.  \n",
    "   - Chaque ligne du CSV correspond √† une capture (une pose) ; vous retrouverez pour chaque landmark sa coordonn√©e X (normalis√©e entre 0 et 1) puis Y (entre 0 et 1).  \n",
    "   - Le fichier CSV ne contient pas d‚Äôen-t√™te ; si besoin, vous pouvez l‚Äôajouter manuellement (par exemple : `x0,y0,x1,y1,...,x32,y32`).\n",
    "\n",
    "5. **Variantes et traitements ult√©rieurs**  \n",
    "   - **Regroupement par action** : pour chaque action (ex. : `saluer`, `pointer`, `marcher`), vous pouvez dupliquer ce notebook (ou modifier `CSV_FILENAME`) pour g√©n√©rer plusieurs fichiers CSV distincts (ex. : `saluer.csv`, `pointer.csv`, ‚Ä¶).  \n",
    "   - **Labeling** : apr√®s la capture, vous pouvez cr√©er un fichier `labels.csv` parall√®le, o√π chaque ligne contient l‚Äô√©tiquette correspondante √† chaque entr√©e de `poses_capturees.csv`.  \n",
    "   - **Pr√©traitements suppl√©mentaires** : normalisation suppl√©mentaire, calcul d‚Äôangles articulaires, filtration des valeurs aberrantes‚Ä¶  \n",
    "   - **Entra√Ænement de mod√®le** : une fois le dataset constitu√©, vous pourrez charger `pandas.read_csv()` pour pr√©parer vos features et labels, puis entra√Æner un classifieur (SVM, r√©seau de neurones, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ad499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Param√®tres de d√©tection et de capture\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "MIN_DETECTION_CONFIDENCE = 0.5       # Confiance minimale pour d√©tecter la pose\n",
    "MIN_TRACKING_CONFIDENCE  = 0.5       # Confiance minimale pour la poursuite\n",
    "MODEL_COMPLEXITY         = 1         # Complexit√© du mod√®le MediaPipe (0, 1 ou 2)\n",
    "VIDEO_SOURCE             = 0         # Index de la cam√©ra (0 = premi√®re cam√©ra)\n",
    "\n",
    "# Nom du fichier CSV dans lequel on sauvegardera les poses\n",
    "CSV_FILENAME = \"poses_capturees.csv\"\n",
    "\n",
    "# Dossier de sortie (pour s‚Äôassurer que le fichier sera cr√©√© dans un dossier sp√©cifique)\n",
    "OUTPUT_DIR = \"./data_poses\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)  # Cr√©ation du dossier s‚Äôil n‚Äôexiste pas\n",
    "\n",
    "# Liste qui contiendra toutes les poses captur√©es (chaque pose = liste de 66 cha√Ænes x,y)\n",
    "pose_data = []\n",
    "\n",
    "# Initialisation de l‚Äôobjet Pose ; la cam√©ra sera ouverte lors de la boucle\n",
    "pose_tracker = Pose(MIN_DETECTION_CONFIDENCE,\n",
    "                    MIN_TRACKING_CONFIDENCE,\n",
    "                    MODEL_COMPLEXITY,\n",
    "                    VIDEO_SOURCE)\n",
    "\n",
    "# Initialisation de MediaPipe pour l‚Äôaffichage des landmarks\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose    = mp.solutions.pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32aa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ D√©marrage de la capture vid√©o. Appuyez sur 'a' pour capturer une pose, 'q' ou 'Esc' pour quitter.\n",
      "‚úîÔ∏è  Pose captur√©e ! Nombre total de poses : 1\n",
      "‚ùó Quitter et sauvegarder les poses...\n",
      "‚úÖ Donn√©es sauvegard√©es dans ¬´ ./data_poses\\poses_capturees.csv ¬ª. Total de poses : 1\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Boucle principale : capture vid√©o, d√©tection de la pose, affichage,\n",
    "# capture au clavier, puis sauvegarde CSV √† la sortie.\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Ouvrir la webcam\n",
    "cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "\n",
    "# Cr√©er un contexte MediaPipe Pose pour la d√©tection en temps r√©el\n",
    "with mp_pose.Pose(min_detection_confidence=MIN_DETECTION_CONFIDENCE,\n",
    "                  min_tracking_confidence=MIN_TRACKING_CONFIDENCE,\n",
    "                  model_complexity=MODEL_COMPLEXITY) as pose:\n",
    "\n",
    "    print(\"D√©marrage de la capture vid√©o. Appuyez sur 'a' pour capturer une pose, 'q' ou 'Esc' pour quitter.\")\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Impossible de lire l'image de la cam√©ra.\")\n",
    "            break\n",
    "\n",
    "        # Miroir horizontal pour plus d‚Äôergonomie\n",
    "        image = cv2.flip(frame, 1)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # D√©tection de la pose sur l‚Äôimage RGB\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        # Si des landmarks de pose sont trouv√©s, on les dessine\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2)\n",
    "            )\n",
    "\n",
    "        # Afficher l‚Äôimage trait√©e (avec squelette)\n",
    "        cv2.imshow(\"Acquisition de Poses\", image)\n",
    "\n",
    "        # Attendre 5 ms pour la d√©tection d‚Äôune touche\n",
    "        key = cv2.waitKey(5) & 0xFF\n",
    "\n",
    "        if key == ord('a'):\n",
    "            # Capturer la pose courante sous forme de vecteur\n",
    "            vec = pose_tracker._toVector(results.pose_landmarks)\n",
    "            if vec:\n",
    "                pose_data.append(vec)\n",
    "                print(f\"Pose captur√©e ! Nombre total de poses : {len(pose_data)}\")\n",
    "            else:\n",
    "                print(\"Aucune pose d√©tect√©e, rien n'est ajout√©.\")\n",
    "\n",
    "        elif key == ord('q') or key == 27:  # 27 = Touche √âchap\n",
    "            print(\"Quitter et sauvegarder les poses...\")\n",
    "            # Construire le chemin complet du fichier CSV\n",
    "            chemin_csv = os.path.join(OUTPUT_DIR, CSV_FILENAME)\n",
    "            with open(chemin_csv, \"w\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                # √âcrire chaque ligne (chaque vecteur de 66 valeurs)\n",
    "                for row in pose_data:\n",
    "                    writer.writerow(row)\n",
    "            print(f\"Donn√©es sauvegard√©es dans ¬´ {chemin_csv} ¬ª. Total de poses : {len(pose_data)}\")\n",
    "            break\n",
    "\n",
    "    # Lib√©ration des ressources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
